"""ä½¿ç”¨SQLiteçš„ç®€åŒ–é…ç½®å’Œå¯¼å…¥è„šæœ¬ï¼ˆæ— éœ€MySQLï¼‰"""
import asyncio
import sys
import pandas as pd
from pathlib import Path
import sqlite3

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


def setup_sqlite_database():
    """è®¾ç½®SQLiteæ•°æ®åº“"""
    print("=" * 60)
    print("ä½¿ç”¨ SQLite æ•°æ®åº“ï¼ˆæ— éœ€MySQLï¼‰")
    print("=" * 60)
    print()
    
    db_path = Path(__file__).parent / "xyzrank.db"
    
    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    # åˆ›å»ºè¡¨
    print("ğŸ“ åˆ›å»ºæ•°æ®è¡¨...")
    
    # Podcastsè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS podcasts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            xyz_id VARCHAR(64) UNIQUE NOT NULL,
            name VARCHAR(255) NOT NULL,
            rss_url VARCHAR(512),
            cover_url VARCHAR(512),
            category VARCHAR(128),
            description TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # PodcastDailyMetricè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS podcast_daily_metrics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            podcast_id INTEGER NOT NULL,
            snapshot_date DATE NOT NULL,
            subscriber_count INTEGER NOT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (podcast_id) REFERENCES podcasts(id) ON DELETE CASCADE,
            UNIQUE(podcast_id, snapshot_date)
        )
    """)
    
    # ScrapeRunè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS scrape_runs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            started_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            completed_at DATETIME,
            status VARCHAR(32) DEFAULT 'running',
            total_podcasts INTEGER,
            successful_count INTEGER,
            failed_count INTEGER,
            error_message TEXT
        )
    """)
    
    # åˆ›å»ºç´¢å¼•
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_podcasts_xyz_id ON podcasts(xyz_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_podcast_id ON podcast_daily_metrics(podcast_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_date ON podcast_daily_metrics(snapshot_date)")
    
    conn.commit()
    conn.close()
    
    print(f"âœ… æ•°æ®åº“å·²åˆ›å»º: {db_path}")
    print()
    return str(db_path)


async def import_to_sqlite(file_path: str, limit: int = None):
    """å¯¼å…¥æ•°æ®åˆ°SQLite"""
    print("=" * 60)
    print("å¯¼å…¥æ•°æ®åˆ° SQLite")
    print("=" * 60)
    print()
    
    # è¯»å–æ–‡ä»¶
    file_ext = Path(file_path).suffix.lower()
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {file_path}")
    
    if file_ext == '.csv':
        df = pd.read_csv(file_path)
    else:
        df = pd.read_excel(file_path)
    
    if limit:
        df = df.head(limit)
        print(f"âš ï¸  é™åˆ¶å¯¼å…¥æ•°é‡: {limit}")
    
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print()
    
    # è¿æ¥æ•°æ®åº“
    db_path = Path(__file__).parent / "xyzrank.db"
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    created_count = 0
    skipped_count = 0
    error_count = 0
    errors = []
    
    print("ğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®...")
    print()
    
    # æ‰¹é‡å¤„ç†
    batch_size = 100
    total = len(df)
    
    for batch_start in range(0, total, batch_size):
        batch_end = min(batch_start + batch_size, total)
        batch_df = df.iloc[batch_start:batch_end]
        
        print(f"å¤„ç†æ‰¹æ¬¡: {batch_start + 1}-{batch_end}/{total} ({batch_end/total*100:.1f}%)...")
        
        for idx, row in batch_df.iterrows():
            try:
                # æå–æ•°æ®
                album_id = str(row.get('album_id', '')).strip()
                album_name = str(row.get('album_name', '')).strip()
                
                if not album_id or not album_name or album_id == 'nan' or album_name == 'nan':
                    error_count += 1
                    errors.append(f"ç¬¬ {idx + 2} è¡Œ: album_id æˆ– album_name ä¸ºç©º")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("SELECT id FROM podcasts WHERE xyz_id = ?", (album_id,))
                if cursor.fetchone():
                    skipped_count += 1
                    continue
                
                # å‡†å¤‡æ•°æ®
                category = None
                if pd.notna(row.get('category')):
                    category = str(row['category']).strip()
                
                description = None
                if pd.notna(row.get('summary')):
                    description = str(row['summary']).strip()
                
                # æ’å…¥æ•°æ®
                cursor.execute("""
                    INSERT INTO podcasts (xyz_id, name, category, description)
                    VALUES (?, ?, ?, ?)
                """, (album_id, album_name, category, description))
                
                created_count += 1
                
            except Exception as e:
                error_count += 1
                error_msg = f"ç¬¬ {idx + 2} è¡Œ: {str(e)}"
                errors.append(error_msg)
                if error_count <= 5:
                    print(f"  âŒ {error_msg}")
        
        # æäº¤æ‰¹æ¬¡
        conn.commit()
        print(f"  âœ… å·²æäº¤æ‰¹æ¬¡")
    
    conn.close()
    
    print()
    print("=" * 60)
    print("å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»è®°å½•æ•°: {total}")
    print(f"âœ… æˆåŠŸåˆ›å»º: {created_count}")
    print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {skipped_count}")
    print(f"âŒ é”™è¯¯æ•°: {error_count}")
    
    if errors and error_count <= 20:
        print()
        print("é”™è¯¯è¯¦æƒ…ï¼ˆå‰20ä¸ªï¼‰:")
        for error in errors[:20]:
            print(f"  - {error}")
    
    print()
    print("=" * 60)
    print(f"âœ… æ•°æ®å·²å¯¼å…¥åˆ°: {db_path}")
    print("=" * 60)


async def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 60)
    print("XYZRank æ•°æ®å¯¼å…¥å·¥å…·ï¼ˆSQLiteç‰ˆæœ¬ï¼‰")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    limit = None
    if len(sys.argv) > 1:
        try:
            limit = int(sys.argv[1])
            print(f"âš ï¸  æµ‹è¯•æ¨¡å¼: å°†åªå¯¼å…¥å‰ {limit} æ¡æ•°æ®")
        except ValueError:
            print(f"âš ï¸  æ— æ•ˆçš„æ•°é‡å‚æ•°: {sys.argv[1]}ï¼Œå°†å¯¼å…¥å…¨éƒ¨æ•°æ®")
    print()
    
    # è®¾ç½®æ•°æ®åº“
    db_path = setup_sqlite_database()
    
    # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    possible_paths = [
        project_root / "å°å®‡å®™å…¨é‡ä¸“è¾‘.csv",
        project_root / "å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx",
        project_root / "å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv",
        Path("/Users/mateng/xyzrank_v6/å°å®‡å®™å…¨é‡ä¸“è¾‘.csv"),
        Path("/Users/mateng/xyzrank_v6/å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv"),
        Path("/Users/mateng/xyzrank_v6/å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx"),
        Path("å°å®‡å®™å…¨é‡ä¸“è¾‘.csv"),
        Path("å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv"),
        Path("å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx"),
    ]
    
    file_path = None
    for path in possible_paths:
        if path.exists():
            file_path = path
            break
    
    if not file_path:
        print("âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        print("å°è¯•çš„è·¯å¾„:")
        for path in possible_paths:
            print(f"  - {path}")
        return
    
    print(f"ğŸ“ ä½¿ç”¨æ–‡ä»¶: {file_path}")
    print()
    
    # å¯¼å…¥æ•°æ®
    await import_to_sqlite(str(file_path), limit=limit)


if __name__ == "__main__":
    asyncio.run(main())

