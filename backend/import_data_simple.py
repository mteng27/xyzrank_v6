"""ç®€åŒ–çš„æ•°æ®å¯¼å…¥è„šæœ¬ - ä¸ä¾èµ–æ•°æ®åº“è¿æ¥ï¼Œç›´æ¥ä½¿ç”¨API"""
import requests
import pandas as pd
from pathlib import Path
import json
import sys

BASE_URL = "http://localhost:8000"


def import_via_api(file_path: str, base_url: str = BASE_URL):
    """é€šè¿‡APIå¯¼å…¥æ•°æ®"""
    print("=" * 60)
    print("é€šè¿‡APIå¯¼å…¥æ’­å®¢æ•°æ®")
    print("=" * 60)
    print()
    
    # è¯»å–æ–‡ä»¶ï¼ˆæ”¯æŒExcelå’ŒCSVï¼‰
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {file_path}")
    file_ext = Path(file_path).suffix.lower()
    if file_ext == '.csv':
        df = pd.read_csv(file_path)
    else:
        df = pd.read_excel(file_path)
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print()
    
    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    try:
        response = requests.get(f"{base_url}/health", timeout=5)
        if response.status_code != 200:
            print(f"âŒ æœåŠ¡æœªæ­£å¸¸è¿è¡Œ (çŠ¶æ€ç : {response.status_code})")
            return
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        print(f"è¯·ç¡®ä¿æœåŠ¡å·²å¯åŠ¨: uvicorn app.main:app --reload")
        return
    
    print("âœ… æœåŠ¡è¿æ¥æ­£å¸¸")
    print()
    
    # å‡†å¤‡æ•°æ®
    created_count = 0
    skipped_count = 0
    error_count = 0
    errors = []
    
    print("ğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®...")
    print()
    
    # æ‰¹é‡å¯¼å…¥ï¼ˆæ¯æ¬¡100æ¡ï¼‰
    batch_size = 100
    total_batches = (len(df) + batch_size - 1) // batch_size
    
    for batch_num in range(total_batches):
        start_idx = batch_num * batch_size
        end_idx = min(start_idx + batch_size, len(df))
        batch_df = df.iloc[start_idx:end_idx]
        
        print(f"å¤„ç†æ‰¹æ¬¡ {batch_num + 1}/{total_batches} (è¡Œ {start_idx + 1}-{end_idx})...")
        
        for idx, row in batch_df.iterrows():
            try:
                # å‡†å¤‡æ•°æ®
                album_id = str(row.get('album_id', '')).strip()
                album_name = str(row.get('album_name', '')).strip()
                
                if not album_id or not album_name or album_id == 'nan' or album_name == 'nan':
                    error_count += 1
                    errors.append(f"ç¬¬ {idx + 2} è¡Œ: album_id æˆ– album_name ä¸ºç©º")
                    continue
                
                # æ„å»ºè¯·æ±‚æ•°æ®
                podcast_data = {
                    "xyz_id": album_id,
                    "name": album_name,
                }
                
                # æ·»åŠ å¯é€‰å­—æ®µ
                if pd.notna(row.get('category')):
                    podcast_data["category"] = str(row['category']).strip()
                
                if pd.notna(row.get('summary')):
                    podcast_data["description"] = str(row['summary']).strip()
                
                # å‘é€è¯·æ±‚
                response = requests.post(
                    f"{base_url}/api/podcasts/",
                    json=podcast_data,
                    timeout=10
                )
                
                if response.status_code == 201:
                    created_count += 1
                elif response.status_code == 400 and "already exists" in response.text:
                    skipped_count += 1
                else:
                    error_count += 1
                    error_msg = f"ç¬¬ {idx + 2} è¡Œ: HTTP {response.status_code}"
                    try:
                        error_detail = response.json().get('detail', '')
                        error_msg += f" - {error_detail}"
                    except:
                        pass
                    errors.append(error_msg)
                    if error_count <= 5:  # åªæ‰“å°å‰5ä¸ªé”™è¯¯
                        print(f"  âš ï¸  {error_msg}")
                
            except Exception as e:
                error_count += 1
                error_msg = f"ç¬¬ {idx + 2} è¡Œ: {str(e)}"
                errors.append(error_msg)
                if error_count <= 5:
                    print(f"  âŒ {error_msg}")
        
        # æ˜¾ç¤ºè¿›åº¦
        processed = end_idx
        print(f"  å·²å¤„ç†: {processed}/{len(df)} ({processed/len(df)*100:.1f}%)")
        print()
    
    # æ˜¾ç¤ºç»“æœ
    print("=" * 60)
    print("å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print(f"âœ… æˆåŠŸåˆ›å»º: {created_count}")
    print(f"â­ï¸  è·³è¿‡ï¼ˆå·²å­˜åœ¨ï¼‰: {skipped_count}")
    print(f"âŒ é”™è¯¯æ•°: {error_count}")
    
    if errors and error_count <= 20:
        print()
        print("é”™è¯¯è¯¦æƒ…:")
        for error in errors[:20]:
            print(f"  - {error}")
    
    print()
    print("=" * 60)


if __name__ == "__main__":
    # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    possible_paths = [
        project_root / "å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx",
        project_root / "å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv",
        Path("/Users/mateng/xyzrank_v6/å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx"),
        Path("/Users/mateng/xyzrank_v6/å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv"),
        Path("å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx"),
        Path("å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.csv"),
    ]
    
    excel_path = None
    for path in possible_paths:
        try:
            if path.exists():
                excel_path = path
                break
        except:
            continue
    
    if not excel_path:
        print("âŒ Excelæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•çš„è·¯å¾„:")
        for path in possible_paths:
            print(f"  - {path}")
        print(f"\nå½“å‰å·¥ä½œç›®å½•: {Path.cwd()}")
        print("è¯·ç¡®ä¿Excelæ–‡ä»¶åœ¨é¡¹ç›®æ ¹ç›®å½•æˆ–æŒ‡å®šæ­£ç¡®è·¯å¾„")
        print("\næˆ–è€…æ‰‹åŠ¨æŒ‡å®šè·¯å¾„:")
        print("  python import_data_simple.py /path/to/å°å®‡å®™ä¸“è¾‘èµ„æ–™-all.xlsx")
        sys.exit(1)
    
    print(f"ğŸ“ ä½¿ç”¨Excelæ–‡ä»¶: {excel_path}")
    print()
    import_via_api(str(excel_path))

