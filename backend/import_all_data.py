"""å®Œæ•´å¯¼å…¥ä¸¤ä¸ªæ•°æ®è¡¨æ ¼åˆ°æ•°æ®åº“"""
import asyncio
import sys
import pandas as pd
from pathlib import Path
import sqlite3
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))


def setup_database():
    """è®¾ç½®æ•°æ®åº“è¡¨"""
    print("=" * 60)
    print("è®¾ç½®æ•°æ®åº“")
    print("=" * 60)
    print()
    
    db_path = Path(__file__).parent / "xyzrank.db"
    
    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    print("ğŸ“ åˆ›å»ºæ•°æ®è¡¨...")
    
    # Podcastsè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS podcasts (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            xyz_id VARCHAR(64) UNIQUE NOT NULL,
            name VARCHAR(255) NOT NULL,
            rss_url VARCHAR(512),
            cover_url VARCHAR(512),
            category VARCHAR(128),
            description TEXT,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # PodcastDailyMetricè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS podcast_daily_metrics (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            podcast_id INTEGER NOT NULL,
            snapshot_date DATE NOT NULL,
            subscriber_count INTEGER NOT NULL,
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (podcast_id) REFERENCES podcasts(id) ON DELETE CASCADE,
            UNIQUE(podcast_id, snapshot_date)
        )
    """)
    
    # ScrapeRunè¡¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS scrape_runs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            started_at DATETIME DEFAULT CURRENT_TIMESTAMP,
            completed_at DATETIME,
            status VARCHAR(32) DEFAULT 'running',
            total_podcasts INTEGER,
            successful_count INTEGER,
            failed_count INTEGER,
            error_message TEXT
        )
    """)
    
    # åˆ›å»ºç´¢å¼•
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_podcasts_xyz_id ON podcasts(xyz_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_podcast_id ON podcast_daily_metrics(podcast_id)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_date ON podcast_daily_metrics(snapshot_date)")
    
    conn.commit()
    conn.close()
    
    print(f"âœ… æ•°æ®åº“è¡¨å·²åˆ›å»º: {db_path}")
    print()
    return str(db_path)


def import_podcasts(file_path: str):
    """å¯¼å…¥æ’­å®¢åŸºæœ¬ä¿¡æ¯"""
    print("=" * 60)
    print("æ­¥éª¤ 1: å¯¼å…¥æ’­å®¢åŸºæœ¬ä¿¡æ¯ï¼ˆå…¨é‡ä¸“è¾‘ï¼‰")
    print("=" * 60)
    print()
    
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {file_path}")
    df = pd.read_csv(file_path)
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print()
    
    # æ›´ä¸¥æ ¼åœ°è¿‡æ»¤ï¼šæ’é™¤NaNã€ç©ºå­—ç¬¦ä¸²å’Œ'nan'å­—ç¬¦ä¸²
    def is_valid_id(val):
        if pd.isna(val):
            return False
        val_str = str(val).strip()
        return val_str and val_str.lower() != 'nan' and val_str != ''
    
    def is_valid_name(val):
        if pd.isna(val):
            return False
        val_str = str(val).strip()
        return val_str and val_str.lower() != 'nan' and val_str != ''
    
    df_valid = df[
        df['album_id'].apply(is_valid_id) & 
        df['album_name'].apply(is_valid_name)
    ].copy()
    print(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid)} (è¿‡æ»¤äº† {len(df) - len(df_valid)} æ¡æ— æ•ˆæ•°æ®)")
    print()
    
    db_path = Path(__file__).parent / "xyzrank.db"
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    created_count = 0
    updated_count = 0
    skipped_count = 0
    error_count = 0
    errors = []
    
    print("ğŸš€ å¼€å§‹å¯¼å…¥æ’­å®¢æ•°æ®...")
    print()
    
    batch_size = 100
    total = len(df_valid)
    
    for batch_start in range(0, total, batch_size):
        batch_end = min(batch_start + batch_size, total)
        batch_df = df_valid.iloc[batch_start:batch_end]
        
        print(f"å¤„ç†æ‰¹æ¬¡: {batch_start + 1}-{batch_end}/{total} ({batch_end/total*100:.1f}%)...")
        
        for idx, row in batch_df.iterrows():
            try:
                album_id = str(row['album_id']).strip()
                album_name = str(row['album_name']).strip()
                
                if not album_id or not album_name:
                    error_count += 1
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("SELECT id FROM podcasts WHERE xyz_id = ?", (album_id,))
                existing = cursor.fetchone()
                
                if existing:
                    # æ›´æ–°ç°æœ‰è®°å½•
                    category = str(row['category']).strip() if pd.notna(row.get('category')) else None
                    description = str(row['summary']).strip() if pd.notna(row.get('summary')) else None
                    
                    cursor.execute("""
                        UPDATE podcasts 
                        SET name = ?, category = ?, description = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE xyz_id = ?
                    """, (album_name, category, description, album_id))
                    updated_count += 1
                else:
                    # åˆ›å»ºæ–°è®°å½•
                    category = str(row['category']).strip() if pd.notna(row.get('category')) else None
                    description = str(row['summary']).strip() if pd.notna(row.get('summary')) else None
                    
                    cursor.execute("""
                        INSERT INTO podcasts (xyz_id, name, category, description)
                        VALUES (?, ?, ?, ?)
                    """, (album_id, album_name, category, description))
                    created_count += 1
                
            except Exception as e:
                error_count += 1
                if error_count <= 5:
                    errors.append(f"ç¬¬ {idx + 2} è¡Œ: {str(e)}")
        
        conn.commit()
        print(f"  âœ… å·²æäº¤æ‰¹æ¬¡")
    
    conn.close()
    
    print()
    print("=" * 60)
    print("æ’­å®¢æ•°æ®å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»è®°å½•æ•°: {total}")
    print(f"âœ… æˆåŠŸåˆ›å»º: {created_count}")
    print(f"ğŸ”„ æ›´æ–°: {updated_count}")
    print(f"âŒ é”™è¯¯æ•°: {error_count}")
    print()
    
    return created_count + updated_count


def import_subscriber_metrics(file_path: str):
    """å¯¼å…¥è®¢é˜…é‡å†å²æ•°æ®"""
    print("=" * 60)
    print("æ­¥éª¤ 2: å¯¼å…¥è®¢é˜…é‡å†å²æ•°æ®ï¼ˆéƒ¨åˆ†è®¢é˜…é‡ï¼‰")
    print("=" * 60)
    print()
    
    print(f"ğŸ“– è¯»å–æ–‡ä»¶: {file_path}")
    df = pd.read_csv(file_path)
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print()
    
    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    df_valid = df[
        df['album_id'].notna() & 
        df['subscribe_count'].notna() & 
        df['update_time'].notna()
    ].copy()
    print(f"æœ‰æ•ˆè®°å½•æ•°: {len(df_valid)} (è¿‡æ»¤äº† {len(df) - len(df_valid)} æ¡æ— æ•ˆæ•°æ®)")
    print()
    
    db_path = Path(__file__).parent / "xyzrank.db"
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    # åˆ›å»ºalbum_idåˆ°podcast_idçš„æ˜ å°„
    print("ğŸ“‹ åˆ›å»ºæ’­å®¢IDæ˜ å°„...")
    cursor.execute("SELECT id, xyz_id FROM podcasts")
    id_mapping = {xyz_id: pid for pid, xyz_id in cursor.fetchall()}
    print(f"âœ… æ‰¾åˆ° {len(id_mapping)} ä¸ªæ’­å®¢")
    print()
    
    imported_count = 0
    skipped_count = 0
    error_count = 0
    errors = []
    
    print("ğŸš€ å¼€å§‹å¯¼å…¥è®¢é˜…é‡æ•°æ®...")
    print()
    
    batch_size = 500
    total = len(df_valid)
    
    for batch_start in range(0, total, batch_size):
        batch_end = min(batch_start + batch_size, total)
        batch_df = df_valid.iloc[batch_start:batch_end]
        
        print(f"å¤„ç†æ‰¹æ¬¡: {batch_start + 1}-{batch_end}/{total} ({batch_end/total*100:.1f}%)...")
        
        for idx, row in batch_df.iterrows():
            try:
                album_id = str(row['album_id']).strip()
                
                # æŸ¥æ‰¾å¯¹åº”çš„podcast_id
                podcast_id = id_mapping.get(album_id)
                if not podcast_id:
                    skipped_count += 1
                    continue
                
                # è§£æè®¢é˜…æ•°é‡
                try:
                    subscriber_count = int(float(row['subscribe_count']))
                except (ValueError, TypeError):
                    error_count += 1
                    continue
                
                # è§£ææ—¥æœŸï¼ˆä»update_timeæå–æ—¥æœŸéƒ¨åˆ†ï¼‰
                update_time = str(row['update_time']).strip()
                try:
                    # å°è¯•è§£æISOæ ¼å¼æ—¶é—´
                    if 'T' in update_time:
                        dt = datetime.fromisoformat(update_time.replace('Z', '+00:00'))
                    else:
                        dt = datetime.strptime(update_time, '%Y-%m-%d %H:%M:%S')
                    snapshot_date = dt.date().isoformat()
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•åªæå–æ—¥æœŸéƒ¨åˆ†
                    if 'T' in update_time:
                        snapshot_date = update_time.split('T')[0]
                    else:
                        snapshot_date = update_time[:10]
                
                # æ’å…¥æˆ–æ›´æ–°æŒ‡æ ‡ï¼ˆä½¿ç”¨INSERT OR REPLACEå¤„ç†å”¯ä¸€çº¦æŸï¼‰
                cursor.execute("""
                    INSERT OR REPLACE INTO podcast_daily_metrics 
                    (podcast_id, snapshot_date, subscriber_count)
                    VALUES (?, ?, ?)
                """, (podcast_id, snapshot_date, subscriber_count))
                
                imported_count += 1
                
            except Exception as e:
                error_count += 1
                if error_count <= 10:
                    errors.append(f"ç¬¬ {idx + 2} è¡Œ: {str(e)}")
        
        conn.commit()
        print(f"  âœ… å·²æäº¤æ‰¹æ¬¡ (å·²å¯¼å…¥: {imported_count}, è·³è¿‡: {skipped_count})")
    
    conn.close()
    
    print()
    print("=" * 60)
    print("è®¢é˜…é‡æ•°æ®å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"æ€»è®°å½•æ•°: {total}")
    print(f"âœ… æˆåŠŸå¯¼å…¥: {imported_count}")
    print(f"â­ï¸  è·³è¿‡ï¼ˆæ— å¯¹åº”æ’­å®¢ï¼‰: {skipped_count}")
    print(f"âŒ é”™è¯¯æ•°: {error_count}")
    if errors:
        print()
        print("é”™è¯¯ç¤ºä¾‹ï¼ˆå‰10ä¸ªï¼‰:")
        for error in errors[:10]:
            print(f"  - {error}")
    print()
    
    return imported_count


def verify_import():
    """éªŒè¯å¯¼å…¥ç»“æœ"""
    print("=" * 60)
    print("éªŒè¯å¯¼å…¥ç»“æœ")
    print("=" * 60)
    print()
    
    db_path = Path(__file__).parent / "xyzrank.db"
    conn = sqlite3.connect(str(db_path))
    cursor = conn.cursor()
    
    # ç»Ÿè®¡æ’­å®¢
    cursor.execute("SELECT COUNT(*) FROM podcasts")
    podcast_count = cursor.fetchone()[0]
    
    # ç»Ÿè®¡æŒ‡æ ‡
    cursor.execute("SELECT COUNT(*) FROM podcast_daily_metrics")
    metric_count = cursor.fetchone()[0]
    
    # ç»Ÿè®¡æœ‰æŒ‡æ ‡çš„æ’­å®¢æ•°
    cursor.execute("SELECT COUNT(DISTINCT podcast_id) FROM podcast_daily_metrics")
    podcasts_with_metrics = cursor.fetchone()[0]
    
    # åˆ†ç±»ç»Ÿè®¡
    cursor.execute("""
        SELECT category, COUNT(*) as cnt 
        FROM podcasts 
        WHERE category IS NOT NULL
        GROUP BY category 
        ORDER BY cnt DESC 
        LIMIT 10
    """)
    categories = cursor.fetchall()
    
    # æŒ‡æ ‡æ—¥æœŸèŒƒå›´
    cursor.execute("""
        SELECT MIN(snapshot_date), MAX(snapshot_date), COUNT(DISTINCT snapshot_date)
        FROM podcast_daily_metrics
    """)
    date_range = cursor.fetchone()
    
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  æ’­å®¢æ€»æ•°: {podcast_count}")
    print(f"  è®¢é˜…é‡è®°å½•æ•°: {metric_count}")
    print(f"  æœ‰å†å²æ•°æ®çš„æ’­å®¢æ•°: {podcasts_with_metrics}")
    if date_range[0]:
        print(f"  æ—¥æœŸèŒƒå›´: {date_range[0]} è‡³ {date_range[1]}")
        print(f"  ä¸åŒæ—¥æœŸæ•°: {date_range[2]}")
    print()
    
    print("ğŸ“ˆ åˆ†ç±»ç»Ÿè®¡ï¼ˆå‰10ï¼‰:")
    for cat, cnt in categories:
        print(f"  {cat}: {cnt}")
    print()
    
    conn.close()


async def main():
    """ä¸»å‡½æ•°"""
    print()
    print("=" * 60)
    print("XYZRank å®Œæ•´æ•°æ®å¯¼å…¥å·¥å…·")
    print("=" * 60)
    print()
    
    # è®¾ç½®æ•°æ®åº“
    db_path = setup_database()
    
    # æŸ¥æ‰¾æ–‡ä»¶
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    podcasts_file = project_root / "å°å®‡å®™å…¨é‡ä¸“è¾‘.csv"
    metrics_file = project_root / "å°å®‡å®™æ’­å®¢éƒ¨åˆ†è®¢é˜…é‡.csv"
    
    if not podcasts_file.exists():
        print(f"âŒ æ’­å®¢æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {podcasts_file}")
        return
    
    if not metrics_file.exists():
        print(f"âŒ è®¢é˜…é‡æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {metrics_file}")
        return
    
    # å¯¼å…¥æ’­å®¢æ•°æ®
    podcast_count = import_podcasts(str(podcasts_file))
    
    # å¯¼å…¥è®¢é˜…é‡æ•°æ®
    metric_count = import_subscriber_metrics(str(metrics_file))
    
    # éªŒè¯å¯¼å…¥
    verify_import()
    
    print("=" * 60)
    print("âœ… æ‰€æœ‰æ•°æ®å¯¼å…¥å®Œæˆï¼")
    print("=" * 60)
    print(f"æ•°æ®åº“ä½ç½®: {db_path}")
    print()


if __name__ == "__main__":
    asyncio.run(main())

